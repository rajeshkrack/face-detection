{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('fer2013.csv')\n",
    "\n",
    "print(df.info())\n",
    "# print(df[\"Usage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"shape:{X_train.shape}\")\n",
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "# The main advantage of using the ReLU function over other activation functions is that it does not activate all the neurons at the same time.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 1,914,951\n",
      "Trainable params: 1,914,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "449/449 [==============================] - 172s 382ms/step - loss: 1.7338 - accuracy: 0.2914 - val_loss: 1.5794 - val_accuracy: 0.3722\n",
      "Epoch 2/50\n",
      "449/449 [==============================] - 226s 504ms/step - loss: 1.5103 - accuracy: 0.4062 - val_loss: 1.3896 - val_accuracy: 0.4531\n",
      "Epoch 3/50\n",
      "449/449 [==============================] - 216s 482ms/step - loss: 1.4028 - accuracy: 0.4546 - val_loss: 1.3300 - val_accuracy: 0.4873\n",
      "Epoch 4/50\n",
      "449/449 [==============================] - 231s 515ms/step - loss: 1.3377 - accuracy: 0.4838 - val_loss: 1.2718 - val_accuracy: 0.5060\n",
      "Epoch 5/50\n",
      "449/449 [==============================] - 236s 526ms/step - loss: 1.2956 - accuracy: 0.5027 - val_loss: 1.2636 - val_accuracy: 0.5065\n",
      "Epoch 6/50\n",
      "449/449 [==============================] - 236s 525ms/step - loss: 1.2568 - accuracy: 0.5168 - val_loss: 1.2241 - val_accuracy: 0.5247\n",
      "Epoch 7/50\n",
      "449/449 [==============================] - 217s 483ms/step - loss: 1.2285 - accuracy: 0.5294 - val_loss: 1.2174 - val_accuracy: 0.5269\n",
      "Epoch 8/50\n",
      "449/449 [==============================] - 222s 494ms/step - loss: 1.2097 - accuracy: 0.5348 - val_loss: 1.2200 - val_accuracy: 0.5308\n",
      "Epoch 9/50\n",
      "449/449 [==============================] - 176s 393ms/step - loss: 1.1845 - accuracy: 0.5454 - val_loss: 1.1973 - val_accuracy: 0.5475\n",
      "Epoch 10/50\n",
      "449/449 [==============================] - 175s 390ms/step - loss: 1.1570 - accuracy: 0.5552 - val_loss: 1.2031 - val_accuracy: 0.5478\n",
      "Epoch 11/50\n",
      "449/449 [==============================] - 167s 371ms/step - loss: 1.1455 - accuracy: 0.5620 - val_loss: 1.1745 - val_accuracy: 0.5500\n",
      "Epoch 12/50\n",
      "449/449 [==============================] - 167s 371ms/step - loss: 1.1261 - accuracy: 0.5669 - val_loss: 1.1731 - val_accuracy: 0.5508\n",
      "Epoch 13/50\n",
      "449/449 [==============================] - 169s 376ms/step - loss: 1.1117 - accuracy: 0.5726 - val_loss: 1.1776 - val_accuracy: 0.5561\n",
      "Epoch 14/50\n",
      "449/449 [==============================] - 168s 374ms/step - loss: 1.0962 - accuracy: 0.5812 - val_loss: 1.1549 - val_accuracy: 0.5545\n",
      "Epoch 15/50\n",
      "449/449 [==============================] - 169s 375ms/step - loss: 1.0789 - accuracy: 0.5881 - val_loss: 1.1422 - val_accuracy: 0.5631\n",
      "Epoch 16/50\n",
      "449/449 [==============================] - 169s 376ms/step - loss: 1.0651 - accuracy: 0.5928 - val_loss: 1.1665 - val_accuracy: 0.5578\n",
      "Epoch 17/50\n",
      "449/449 [==============================] - 169s 376ms/step - loss: 1.0517 - accuracy: 0.6007 - val_loss: 1.1523 - val_accuracy: 0.5665\n",
      "Epoch 18/50\n",
      "449/449 [==============================] - 171s 381ms/step - loss: 1.0408 - accuracy: 0.6035 - val_loss: 1.1520 - val_accuracy: 0.5656\n",
      "Epoch 19/50\n",
      "449/449 [==============================] - 170s 378ms/step - loss: 1.0265 - accuracy: 0.6102 - val_loss: 1.1376 - val_accuracy: 0.5670\n",
      "Epoch 20/50\n",
      "449/449 [==============================] - 171s 380ms/step - loss: 1.0065 - accuracy: 0.6149 - val_loss: 1.1520 - val_accuracy: 0.5681\n",
      "Epoch 21/50\n",
      "449/449 [==============================] - 136s 302ms/step - loss: 0.9965 - accuracy: 0.6155 - val_loss: 1.1698 - val_accuracy: 0.5598\n",
      "Epoch 22/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.9848 - accuracy: 0.6258 - val_loss: 1.1634 - val_accuracy: 0.5662\n",
      "Epoch 23/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.9689 - accuracy: 0.6313 - val_loss: 1.1717 - val_accuracy: 0.5673\n",
      "Epoch 24/50\n",
      "449/449 [==============================] - 135s 300ms/step - loss: 0.9608 - accuracy: 0.6332 - val_loss: 1.1722 - val_accuracy: 0.5676\n",
      "Epoch 25/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.9573 - accuracy: 0.6342 - val_loss: 1.1860 - val_accuracy: 0.5600\n",
      "Epoch 26/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.9374 - accuracy: 0.6437 - val_loss: 1.1837 - val_accuracy: 0.5706\n",
      "Epoch 27/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.9220 - accuracy: 0.6485 - val_loss: 1.1759 - val_accuracy: 0.5704\n",
      "Epoch 28/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.9126 - accuracy: 0.6528 - val_loss: 1.1914 - val_accuracy: 0.5659\n",
      "Epoch 29/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8985 - accuracy: 0.6610 - val_loss: 1.1715 - val_accuracy: 0.5756\n",
      "Epoch 30/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.8918 - accuracy: 0.6605 - val_loss: 1.1942 - val_accuracy: 0.5731\n",
      "Epoch 31/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8828 - accuracy: 0.6615 - val_loss: 1.1688 - val_accuracy: 0.5745\n",
      "Epoch 32/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8714 - accuracy: 0.6682 - val_loss: 1.1702 - val_accuracy: 0.5726\n",
      "Epoch 33/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.8664 - accuracy: 0.6755 - val_loss: 1.1876 - val_accuracy: 0.5706\n",
      "Epoch 34/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8535 - accuracy: 0.6735 - val_loss: 1.2040 - val_accuracy: 0.5667\n",
      "Epoch 35/50\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 0.8394 - accuracy: 0.6817 - val_loss: 1.1768 - val_accuracy: 0.5731\n",
      "Epoch 36/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8229 - accuracy: 0.6867 - val_loss: 1.2085 - val_accuracy: 0.5704\n",
      "Epoch 37/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8217 - accuracy: 0.6886 - val_loss: 1.2094 - val_accuracy: 0.5773\n",
      "Epoch 38/50\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 0.8121 - accuracy: 0.6975 - val_loss: 1.2194 - val_accuracy: 0.5620\n",
      "Epoch 39/50\n",
      "449/449 [==============================] - 135s 302ms/step - loss: 0.7975 - accuracy: 0.6978 - val_loss: 1.2075 - val_accuracy: 0.5745\n",
      "Epoch 40/50\n",
      "449/449 [==============================] - 134s 299ms/step - loss: 0.7931 - accuracy: 0.7026 - val_loss: 1.2293 - val_accuracy: 0.5740\n",
      "Epoch 41/50\n",
      "449/449 [==============================] - 134s 299ms/step - loss: 0.7835 - accuracy: 0.7061 - val_loss: 1.2209 - val_accuracy: 0.5793\n",
      "Epoch 42/50\n",
      "449/449 [==============================] - 136s 303ms/step - loss: 0.7807 - accuracy: 0.7070 - val_loss: 1.2290 - val_accuracy: 0.5659\n",
      "Epoch 43/50\n",
      "449/449 [==============================] - 155s 345ms/step - loss: 0.7739 - accuracy: 0.7073 - val_loss: 1.2512 - val_accuracy: 0.5726\n",
      "Epoch 44/50\n",
      "449/449 [==============================] - 149s 333ms/step - loss: 0.7554 - accuracy: 0.7119 - val_loss: 1.2674 - val_accuracy: 0.5690\n",
      "Epoch 45/50\n",
      "449/449 [==============================] - 146s 326ms/step - loss: 0.7503 - accuracy: 0.7184 - val_loss: 1.2609 - val_accuracy: 0.5717\n",
      "Epoch 46/50\n",
      "449/449 [==============================] - 148s 329ms/step - loss: 0.7420 - accuracy: 0.7218 - val_loss: 1.2474 - val_accuracy: 0.5715\n",
      "Epoch 47/50\n",
      "449/449 [==============================] - 148s 330ms/step - loss: 0.7359 - accuracy: 0.7236 - val_loss: 1.2619 - val_accuracy: 0.5829\n",
      "Epoch 48/50\n",
      "449/449 [==============================] - 140s 311ms/step - loss: 0.7168 - accuracy: 0.7303 - val_loss: 1.2799 - val_accuracy: 0.5704\n",
      "Epoch 49/50\n",
      "449/449 [==============================] - 149s 331ms/step - loss: 0.7194 - accuracy: 0.7289 - val_loss: 1.2783 - val_accuracy: 0.5754\n",
      "Epoch 50/50\n",
      "449/449 [==============================] - 147s 327ms/step - loss: 0.7018 - accuracy: 0.7388 - val_loss: 1.3046 - val_accuracy: 0.5756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e638b10508>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
